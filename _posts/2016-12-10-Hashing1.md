---
layout: post
title: Hashing I
published: true
categories: Programming
---

Hashing is a Data Structure that allows us to retrieve or update data from any data set in an average O(1) time.  

The problem at hand is how do we improve search time in a very large data set? An analogy to such a data set is our Internet. According to internet data tracking services, the amount of content on the internet doubles every six months. With this amount of data, if we stick to our traditional searching methods, we will resolve the search in O(log n) at the fastest if the data is sorted. If the data is sorted, we can use techniques such as Binary Search; and if the search tree is balanced, it will allow us to find the data in O(log n). Otherwise, we have to search the data set linearly which can be disastrous. 

## How does Hashing works? 

For every object we want to save, we store it in a unique position taken from the object. Imagine we have a function that translates any given object into a unique key. Using this unique key, we immediately knows where to probe in the data set which leads us to object we want to find. This translation of any object into a unique key is called a **Hash Function**.

In the mathematical sense, we are trying to map an key to value. A Map is a relation between 2 sets and using this map, we can find the corresponding values between the 2 sets. An example of a Map is an array. Given the position index which acts as a key, we are able to find the value specified by the position index in the array. The generalised concept of hashing is such that the key does not necessarily be an Integer, but instead it can be any object. As long as the hash function is able to use the provided key to find a unique position in memory. 

Hash table is the associative array that we use to map a key to a value using a hash function.

## Basic Hash Function

A simple example of a Hash Function is using the modulo function. If we want to hash a set of values into a hash table of size N, we can use a simple hash function as follows:

{% highlight none%}
h(value) = value mod N
{% endhighlight %}

For example, we have a set of Strings {"abc", "def", "ghi"} and we want to store them in a table. By using this table, we want to retrieve or update any of the Strings in O(1). 

A simple method to hash these Strings is to associate 'a'=1, 'b'=2, ...., 'z'=26. Then we add up the value of each letter in the string to get a final value, and mod the final value by the size of the table. 

{% highlight none %}
"abc" = 1 + 2 + 3 = 6
"def" = 4 + 5 + 6 = 15
"ghi" = 7 + 8 + 9 = 24
{% endhighlight %}

If we assume the size of the table is 5, then the position to store the values are as follows:

{% highlight none %}
"abc" = 6 mod 5 = 1
"def" = 15 mode 5 = 0
"ghi" = 24 mode 5 = 4
{% endhighlight %}

The resulting table will be as follow

![HashTable]({{ site.baseurl }}/images/2016-12-10-HashTable.png ){: .center-image }

Using this hash table, we can check whether any values exist in the set using O(1). If we want to search whether "abc" exist in the set, we can use the Hash Function to calculate the key of "abc". Then using the key, we check whether the slot is empty. If the slot is not empty, we know that "abc" exist in the set. If the slot is empty, we know that "abc" does not exist in the set. 

## Collision

Collision is when 2 objects after applying the hash function, results in the same key. For example, "def" & "ceg" resolves to the key 0 using the hash function "value mod 5". If we assign "ceg" to key 0 again, the String "def" will be overwritten and lost. 

One way to resolve collision is to use **separate chaining** collision resolution. This method implements a linked list at keys where collision occurs. Hence the hash table becomes an array of linked list. 

![HashTable]({{ site.baseurl }}/images/2016-12-10-SeparateChaining.png ){: .center-image }

Another way to resolve collision is to use **linear probing**. If we cannot insert the object at a particular key, we try the next slot key+1. If key+1 is also occupied, we try key+2 and so on and so forth. This is a simple approach but it requires new thinking about hash tables. How do we ensure O(1) search on average? What if we reach the end of the table? 

## Efficiency of search

If every key only has one value, retrieving and updating a particular data is O(1). Given the value, we can use the hash function to immediately find the key and only a single probe is needed to find the data of interest. 

Factoring in Collision, the worst case scenario for retrieving and updating is O(n). The worst case scenario is that all data collides into the same key. If we use the *separate chaining* collision resolution, then searching will be equivalent to searching through a array of length N. 

#### Simple uniform hashing

Under the simple uniform hashing assumption, we assume that all objects are equally distributed into all key slots. If we have **N** objects to be hashed and a hash table size of m, the average length of each linked list is N/m. We call N/m the load factor α. 

In order to guarantee an expected constant run time, we can use the load factor to decide whether any linked list are getting to long. In the process of hashing the objects, we rehash the hash table if any linked list is longer than the load factor. As such we guarantee the expected constant run time to be O(1+α). If N/m = 1, then the expected constant run time is O(1).

## Universal Hashing & Universal Hash Functions

The ideal hash table is one such that retrieving data is O(1). However in practice it is difficult to find a hash function that is able to resolve a unique key for every object. 

Universal Hashing refers to selecting a hash function at random from a family of hash functions that guarantees a low number of collisions in expectation. A hash function from such universal families guarantee the probability of collision to be 1/m, where m is the number of slots in the hash table. Therefore a search in such hash table is O(α). 

Many universal families are known (for hashing integers, vectors, strings), and their evaluation is often very efficient. One such universal hash function for integers is the following: 

{% highlight none %}
h(k) = ( (ak + b) mod p) mod m
where,
  p is a large prime number
  m is size of hash table
  a,b are integer chosen uniformly at random between 1 to p-1
{% endhighlight %}

## Conclusion
Hashing is a very efficient way to keep average cost of operations to O(1). However collisions are sometimes unavoidable in practice and therefore usually its solved by separate chaining collision resolution. The worse case scenario is O(n), but we try to avoid such cases using good hash functions. A good hash function is one where the results is close to simple uniform hashing assumption. 


## Reference

1. <http://www.cs.cmu.edu/~guna/15-123S11/Lectures/Lecture17.pdf>
2. <https://www.cs.cmu.edu/~adamchik/15-121/lectures/Hashing/hashing.html> 
3. <https://en.wikipedia.org/wiki/Universal_hashing>











